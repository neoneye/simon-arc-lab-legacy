{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "bxeiTLn3OfhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = \"dataset_loda_programs.csv\""
      ],
      "metadata": {
        "id": "YKeE6oZWQM62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiwDOhq5QTJB",
        "outputId": "fe7da8f3-54f7-4eb5-eb81-c7af4f5c0a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 11575297 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHye5oeVQWrG",
        "outputId": "157c9661-cd77-4471-ec29-45d2205986fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mov $1,1\\nlpb $0\\nsub $0,1\\nmov $2,$3\\nmul $2,4\\nmul $3,6\\nadd $3,$1\\nmov $1,$2\\nlpe\\nmov $0,$3\n",
            "mov $1,$0\\nmin $1,1\\nseq $0,66645\\nadd $0,$1\n",
            "mov $3,$0\\npow $0,0\\nsub $0,1\\nlpb $3\\nmov $2,$0\\nmul $2,$3\\nadd $2,1\\nseq $2,22087\\nsub $3,1\\nadd $0,1\\nadd \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J5uYBDUQav5",
        "outputId": "dd717e06-f194-4eba-ae11-b9d601bc3e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['mov $0,4', 'add']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF7gwH_0QibG",
        "outputId": "73345cef-1d65-4e78-a1c5-fceb45a9d26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'm', b'o', b'v', b' ', b'$', b'0', b',', b'4'], [b'a', b'd', b'd']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n"
      ],
      "metadata": {
        "id": "TdmR6pc9QvD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq5cejbuQxik",
        "outputId": "c30f843e-dc73-4c75-bc57-978f0e53b890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[27, 29, 36, 2, 4, 7, 5, 11], [18, 21, 21]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
      ],
      "metadata": {
        "id": "FNMtBU7yQ8U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEtujXEVQ-tK",
        "outputId": "f9af3570-134f-4d76-c3bc-52882934aebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'm', b'o', b'v', b' ', b'$', b'0', b',', b'4'], [b'a', b'd', b'd']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HpUr8HLRCtF",
        "outputId": "eaef3155-a989-4ffa-9cbe-13c3ed0551de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'mov $0,4', b'add'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ],
      "metadata": {
        "id": "EMoYFs4mRGX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMnW_w8FT2u3",
        "outputId": "52627882-70f0-4418-85ae-f8daba7a7dce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(11575297,), dtype=int64, numpy=array([27, 29, 36, ...,  5, 16,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
      ],
      "metadata": {
        "id": "qO5boorcRcEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbnnuFPReZ9",
        "outputId": "6f746060-7a6a-4220-8b96-aa95cf9f889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m\n",
            "o\n",
            "v\n",
            " \n",
            "$\n",
            "1\n",
            ",\n",
            "1\n",
            "\\\n",
            "n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n"
      ],
      "metadata": {
        "id": "F3tfVv1IW2W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu9Uni0eW5KB",
        "outputId": "3eb6ab80-2671-4250-eb99-bbe0628e5ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'm' b'o' b'v' b' ' b'$' b'1' b',' b'1' b'\\\\' b'n' b'l' b'p' b'b' b' '\n",
            " b'$' b'0' b'\\\\' b'n' b's' b'u' b'b' b' ' b'$' b'0' b',' b'1' b'\\\\' b'n'\n",
            " b'm' b'o' b'v' b' ' b'$' b'2' b',' b'$' b'3' b'\\\\' b'n' b'm' b'u' b'l'\n",
            " b' ' b'$' b'2' b',' b'4' b'\\\\' b'n' b'm' b'u' b'l' b' ' b'$' b'3' b','\n",
            " b'6' b'\\\\' b'n' b'a' b'd' b'd' b' ' b'$' b'3' b',' b'$' b'1' b'\\\\' b'n'\n",
            " b'm' b'o' b'v' b' ' b'$' b'1' b',' b'$' b'2' b'\\\\' b'n' b'l' b'p' b'e'\n",
            " b'\\\\' b'n' b'm' b'o' b'v' b' ' b'$' b'0' b',' b'$' b'3' b'\\n' b'm' b'o'\n",
            " b'v' b' ' b'$'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e11zZ1ExW-d4",
        "outputId": "b890fea2-f002-47ec-be10-fb5a69e91ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'mov $1,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $2,$3\\\\nmul $2,4\\\\nmul $3,6\\\\nadd $3,$1\\\\nmov $1,$2\\\\nlpe\\\\nmov $0,$3\\nmov $'\n",
            "b'1,$0\\\\nmin $1,1\\\\nseq $0,66645\\\\nadd $0,$1\\nmov $3,$0\\\\npow $0,0\\\\nsub $0,1\\\\nlpb $3\\\\nmov $2,$0\\\\nmul $2,$3\\\\n'\n",
            "b'add $2,1\\\\nseq $2,22087\\\\nsub $3,1\\\\nadd $0,1\\\\nadd $1,$2\\\\nlpe\\\\nmov $0,$1\\\\ndiv $0,4\\\\nadd $0,1\\nmul $0,6\\\\na'\n",
            "b'dd $0,5\\\\ndiv $0,4\\\\npow $0,2\\nlpb $0\\\\nadd $2,1\\\\nsub $0,$2\\\\nlpe\\\\nsub $0,1\\\\nadd $2,1\\\\nsub $2,$0\\\\nmax $3,$'\n",
            "b'0\\\\nmov $4,$0\\\\nmov $0,$2\\\\nlpb $0\\\\nsub $0,2\\\\nadd $3,$0\\\\nbin $3,$0\\\\nadd $1,$3\\\\nmov $3,$4\\\\nlpe\\\\nmov $0,$1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "q1oFSPL0XKmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw1ju0IRXNV5",
        "outputId": "aa4a6a87-1415-4625-a2d1-e7db14e965d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)\n"
      ],
      "metadata": {
        "id": "pPcPt8S_XQGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUFwGUlDXSr6",
        "outputId": "f6691d6d-39c0-42d8-e75c-b1e4af4974a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'mov $1,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $2,$3\\\\nmul $2,4\\\\nmul $3,6\\\\nadd $3,$1\\\\nmov $1,$2\\\\nlpe\\\\nmov $0,$3\\nmov '\n",
            "Target: b'ov $1,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $2,$3\\\\nmul $2,4\\\\nmul $3,6\\\\nadd $3,$1\\\\nmov $1,$2\\\\nlpe\\\\nmov $0,$3\\nmov $'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq3G9_ctXY8C",
        "outputId": "474c2c81-9fb9-4067-961f-96cd0d9616d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "metadata": {
        "id": "J8d1o8zuXcwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "ywla74f6Xfmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "metadata": {
        "id": "tzqfiyqtXibi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqix022aXlsM",
        "outputId": "3104cdae-e64c-4108-8cd5-f0ff239300b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 39) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYzkga7LXuaj",
        "outputId": "adaca258-4e53-4fb4-d417-99b6ce851ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  9984      \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  39975     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,988,263\n",
            "Trainable params: 3,988,263\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n"
      ],
      "metadata": {
        "id": "Rux9eNFMX2qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9uwoLTcX5RK",
        "outputId": "8d4a1b74-98b3-4f7c-e9c0-19e469a984b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([37,  0,  0,  4, 17, 32, 24,  0, 12, 34,  9, 10,  9, 20,  0,  6, 27,\n",
              "       31, 23, 10, 19,  4, 26, 17,  1, 18, 31, 24, 15, 33, 31,  6, 37,  6,\n",
              "       14,  4,  7, 30, 24,  2, 10, 11,  2, 31, 17, 37, 16,  6, 22, 33, 27,\n",
              "       38, 30, 27,  3, 21,  7, 27,  6, 32, 24, 38, 38, 12, 19, 18, 30, 36,\n",
              "       26, 22, 12,  1, 25,  9,  9,  8, 23, 11,  0, 35, 15,  2, 26, 19, 11,\n",
              "       17, 31, 16, 32, 10,  8, 16, 12, 15, 28, 23, 11, 37, 34, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4SGYsrUX7tB",
        "outputId": "10bb2349-5c5c-462e-bbcd-f4c583e45a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'ax $4,0\\\\ncmp $4,$0\\\\nmul $2,$4\\\\ntrn $2,1\\\\nlpe\\\\nmov $0,$5\\\\nadd $0,1\\nadd $0,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $2'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'w[UNK][UNK]$\\\\rg[UNK]5t232c[UNK]-mqf3b$l\\\\\\naqg8sq-w-7$0pg 34 q\\\\w9-esmxpm\"d0m-rgxx5bapvle5\\ni221f4[UNK]u8 lb4\\\\q9r31958nf4wtq'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "6FX7wAY2YDFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBeNCAbqYFEa",
        "outputId": "04107968-4620-4da3-bdb7-da3e79676fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 39)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(3.663986, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFdvkXbdYHqC",
        "outputId": "b04a6635-0c45-45d1-8d81-3be205f89ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.016552"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "metadata": {
        "id": "s-7A2G_4YKZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "metadata": {
        "id": "JtnJeg0WYM_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n"
      ],
      "metadata": {
        "id": "qbBH4izEYPUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT4oVg8sYRtS",
        "outputId": "cf09b8f0-49b4-46a4-b5b2-a18877ca4a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1790/1790 [==============================] - 23s 11ms/step - loss: 0.5454\n",
            "Epoch 2/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3895\n",
            "Epoch 3/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3645\n",
            "Epoch 4/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3503\n",
            "Epoch 5/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3409\n",
            "Epoch 6/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3348\n",
            "Epoch 7/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3312\n",
            "Epoch 8/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3297\n",
            "Epoch 9/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3301\n",
            "Epoch 10/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3329\n",
            "Epoch 11/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3377\n",
            "Epoch 12/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3482\n",
            "Epoch 13/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3906\n",
            "Epoch 14/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.4609\n",
            "Epoch 15/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.4097\n",
            "Epoch 16/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3923\n",
            "Epoch 17/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.4290\n",
            "Epoch 18/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.4295\n",
            "Epoch 19/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3981\n",
            "Epoch 20/20\n",
            "1790/1790 [==============================] - 21s 11ms/step - loss: 0.3862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n"
      ],
      "metadata": {
        "id": "aUH2EDLndszF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n"
      ],
      "metadata": {
        "id": "bDorqF7Pdwf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['mov $'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uSqrVsOdzSu",
        "outputId": "cea13b2a-fc11-4e8f-de19-b9df1b7913ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mov $5,6\\nmov $6,$3\\nsub $6,$7\\nadd $5,$1\\nmov $6,$7\\nadd $5,1\\nadd $1,$6\\nmov $2,$3\\nmov $3,$2\\nmov $2,$1\\nseq $3,1262209\\nadd $3,1\\nadd $0,$3\\ndiv $0,8\\nadd $0,1\n",
            "pow $0,2\\nmul $0,3\\nsub $0,1\n",
            "add $0,1\\nmov $1,10\\npow $1,$0\\nmov $0,$1\\nadd $0,2\n",
            "mov $5,14\\nmov $2,$0\\nadd $2,2\\nmul $2,24\\nsub $0,1\\nadd $1,$4\\nmul $1,$0\\nadd $3,$5\\nmov $7,$6\\nadd $7,$9\\nadd $9,$10\\nadd $9,$5\\nmov $7,2\\nlpb $0\\nadd $5,1\\nmul $7,$$9\\nsub $3,$4\\nmov $4,$0\\nmax $4,0\\ncmp $4,$0\\nmul $2,$4\\ntrn $2,1\\nlpe\\nmov $0,$5\n",
            "mov $1,2\\npow $1,$0\\nadd $1,1\\nseq $0,40\\nmul $0,$1\n",
            "add $0,2\\npow $0,6\\nsub $0,18\\nmul $0,6\\nadd $0,115\n",
            "mov $1,1\\nadd $0,1\\nlpb $0\\nadd $1,1\\nsub $0,$1\\nmov $2,$0\\nlpe\\nmov $0,$1\\nadd $0,1\n",
            "seq $0,158446\\nsub $0,1\\nseq $0,5\n",
            "seq $0,159557\\nmod $0,9\n",
            "seq $0,32739\\nlpb $0\\nmul $0,2\\ndif $0,0\\nlpe\\ndiv $0,5\n",
            "mov $1,1\\nmov $2,2\\nadd $0,1\\nlpb $0\\nsub $0,1\\nmov $3,$2\\nmul $3,4\\nsub $1,$3\\nadd $3,$1\\nmov $4,$1\\nadd $4,$2\\nmov $4,$3\\nmov $3,$1\\nlpe\\nmov $0,$2\n",
            "lpb $0\\nsub $0,1\\nadd $4,$2\\nadd $1,$3\\nadd $2,$4\\nmov $6 \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.5943562984466553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['mov $1,$0', 'add $0,', 'mov $1,$0'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixsvThSffQVL",
        "outputId": "a35b96c1-5ec9-4cc2-8766-4430f7d0c654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'mov $1,$0\\\\nmov $4,1\\\\nsub $0,1\\\\nmov $2,$0\\\\nlpb $2\\\\nmov $3,$2\\\\ngcd $3,$0\\\\ncmp $3,$2\\\\ncmp $3,0\\\\nmul $3,$0\\\\npow $3,2\\\\nmov $5,$3\\\\nmod $5,16\\\\ncmp $5,0\\\\ndiv $5,321\\\\nlpb $5\\\\ndiv $5,10\\\\nmov $3,8\\\\nbin $3,$1\\\\nmul $3,$2\\\\nadd $1,1\\\\nadd $5,$3\\\\nlpe\\\\nmov $0,$5\\nmov $1,6\\\\npow $1,$0\\\\nmul $0,$1\\\\nadd $0,2\\nmov $1,$0\\\\nseq $1,278573\\\\nseq $0,138220\\\\nmul $1,$0\\\\nmov $0,$1\\\\ndiv $0,4\\nmov $2,$0\\\\nadd $2,2\\\\npow $2,3\\\\nlpb $2\\\\nsub $2,1\\\\nadd $0,$1\\\\nadd $0,1\\\\nsub $2,$0\\\\nbin $2,$0\\\\nmov $3,$4\\\\nbin $3,$1\\\\nadd $1,1\\\\nmul $3,$2\\\\ndiv $3,$1\\\\nadd $5,1\\\\nadd $5,$3\\\\nlpe\\\\nmov $0,$5\\\\nsub $0,1\\nmov $1,1\\\\nmov $4,1\\\\nmov $5,$0\\\\nadd $5,1\\\\nlpb $5\\\\nsub $5,1\\\\nmov $0,$3\\\\nseq $0,5\\\\nsub $0,1\\\\nmov $1,$2\\\\nlpe\\\\nmov $0,$8\\\\nadd $0,1\\nmov $5,$0\\\\nadd $5,1\\\\nlpb $5\\\\nsub $5,1\\\\nmov $0,$3\\\\nseq $0,56649\\\\nsub $0,$4\\\\nadd $1,$4\\\\nmov $4,$0\\\\nlpe\\\\nmov $0,$4\\\\nadd $0,1\\nmov $1,1\\\\nmov $2,$0\\\\nadd $2,6\\\\npow $2,3\\\\nlpb $2\\\\nmov $3,$6\\\\nseq $3,10061\\\\nsub $3,1\\\\ncmp $3,5\\\\nsub $0,$3\\\\nmov $4,$0\\\\nmax $4,0\\\\ncmp $4,$0\\\\nmul $2,$4\\\\nlpe\\\\nmov $0,$5\\\\ndiv $0,2\\nmov $4,$0\\\\nlpb $0\\\\nsub $0,1\\\\nadd $1,$4'\n",
            " b'add $0,6\\\\nsub $0,6\\\\nsub $0,$1\\nadd $0,1\\\\nmov $4,$0\\\\nlpb $0\\\\nsub $0,1\\\\nadd $1,$4\\\\nmov $4,$0\\\\nmax $4,0\\\\ncmp $4,$0\\\\nmul $2,$4\\\\nsub $2,1\\\\nlpe\\\\nmov $0,$1\\nmov $5,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $4,$2\\\\nadd $4,$1\\\\nmul $2,2\\\\nadd $2,$3\\\\nmov $3,$1\\\\nmul $1,3\\\\nadd $2,$1\\\\nmov $1,$6\\\\nmov $6,$3\\\\nmul $6,2\\\\nmul $6,$2\\\\nadd $1,$6\\\\nmul $2,-\\\\nadd $2,$1\\\\nlpe\\\\nmov $0,$2\\nseq $0,47995\\\\nsub $0,1\\\\nseq $0,181825\\nadd $0,1\\\\nmul $0,3\\\\ndiv $0,39\\nmov $1,$0\\\\npow $0,2\\\\nmax $1,1\\\\nmov $2,$1\\\\ngcd $2,$1\\\\nbin $1,$2\\\\nlpb $0\\\\ndiv $2,2\\\\nlpe\\\\nmov $0,$1\\nmov $2,1\\\\nsub $0,2\\\\nlpb $0\\\\nsub $0,1\\\\nmul $2,4\\\\nadd $2,$1\\\\nadd $3,$1\\\\nmul $1,7\\\\nlpe\\\\nmov $0,$1\\\\ndiv $0,2\\\\nadd $0,1\\nadd $0,1\\\\nmov $2,$0\\\\npow $2,2\\\\nlpb $2\\\\nmov $3,$1\\\\nseq $3,50402\\\\ngcd $3,2\\\\nsub $0,$3\\\\nadd $0,1\\\\nadd $1,1\\\\nmov $4,$0\\\\nmax $4,0\\\\ncmp $4,$0\\\\nmul $2,$4\\\\nlpe\\\\nmov $0,$5\\nmov $4,1\\\\nlpb $0\\\\nmov $2,$0\\\\nsub $2,1\\\\nsub $4,1\\\\nsub $0,1\\\\nmul $3,3\\\\nadd $3,$1\\\\nmul $1,$2\\\\nlpe\\\\nadd $1,$6\\\\nmov $0,$1\\\\nmul $0,2\\nlpb $0\\\\nadd $2,1\\\\nsub $0,$2\\\\nlpe\\\\nmov $1,$2\\\\nbin $1,$0\\\\nsub $2,$0\\\\nlpb $0\\\\nmov $3,$0\\\\nsub $3,2\\\\n'\n",
            " b'mov $1,$0\\\\nseq $1,31906\\\\nmod $0,2\\\\nsub $0,$1\\nseq $0,310973\\\\nmul $0,2\\\\ndiv $0,4\\nmov $1,2\\\\npow $1,$0\\\\nadd $0,2\\\\nmul $1,$0\\\\nadd $0,$1\\\\nadd $0,2\\nmov $2,$0\\\\nadd $2,1\\\\nmov $4,$0\\\\nadd $4,1\\\\nlpb $4\\\\nsub $4,1\\\\nmov $3,$0\\\\nsub $3,1\\\\nmul $3,$4\\\\ndiv $0,2\\\\nsub $2,$0\\\\nmov $0,$2\\\\nsub $0,1\\\\nseq $0,142\\\\nadd $3,$0\\\\nlpe\\\\nmov $0,$3\\\\ndiv $0,9\\\\nadd $0,1\\nmov $2,1\\\\nmov $4,1\\\\nsub $0,1\\\\nlpb $0\\\\nsub $4,1\\\\nmul $5,$2\\\\ntrn $4,3\\\\ncmp $6,0\\\\nsub $0,$6\\\\nsub $2,$0\\\\nadd $2,$0\\\\nbin $2,$0\\\\nmul $1,$2\\\\nsub $1,2\\\\nbin $0,$1\\\\nsub $1,$0\\\\nmov $0,$1\\nmov $1,1\\\\nmov $2,2\\\\nmov $4,1\\\\nadd $0,1\\\\nlpb $0\\\\nsub $0,1\\\\nmov $1,$2\\\\nseq $1,156502\\\\nmul $3,$2\\\\ndiv $3,$1\\\\nsub $1,$3\\\\nadd $5,$1\\\\nlpe\\\\nmov $4,$2\\\\nadd $4,3\\\\nmul $4,$3\\\\nadd $4,1\\\\nmov $5,$6\\\\nlpb $0\\\\ndif $0,$1\\\\ndif $1,2\\\\nmov $3,$2\\\\nmod $3,2\\\\nadd $4,1\\\\nlpe\\\\nmov $0,$4\\nadd $0,1\\\\nseq $0,51073\\\\ndiv $0,2\\nmov $1,1\\\\nsub $0,1\\\\nlpb $0\\\\nadd $1,1\\\\nsub $0,$1\\\\nlpe\\\\nsub $1,$0\\\\nmul $1,2\\\\ntrn $1,$0\\\\nbin $0,2\\\\ndiv $0,$1\\nmov $6,1\\\\nmov $7,$0\\\\nadd $7,4\\\\nlpb $7\\\\nsub $8,1\\\\nmul $1,$3\\\\nmul $1,$0\\\\nmul $1,2\\\\ndiv $1,$2\\\\nmod $1,1'], shape=(3,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.5701823234558105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xDA97G4fjeC",
        "outputId": "619d9375-d1e9-4f7f-8f10-98a6b51241ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f510a623910>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['lpb $0'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEKtfYbkfzbq",
        "outputId": "69dcc8b7-213d-4de6-8481-a7daff1ec76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lpb $0\\nadd $1,2\\nsub $0,$1\\nlpe\\nsub $1,$0\\nmul $1,2\\nmov $4,$3\\ndiv $4,2\\nlpe\\nsub $0,1\\nlpe\\nmov $0,$2\n",
            "\n"
          ]
        }
      ]
    }
  ]
}